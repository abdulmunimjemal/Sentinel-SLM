{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Sentinel-SLM: Comprehensive Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Objective:** Analyze the distribution, balance, and linguistic properties of the aggregated Sentinel-SLM dataset (1.6M+ samples) across 8 safety categories.\n",
    "\n",
    "**Dataset:** `data/processed/final_augmented_dataset_enriched.parquet` (or standard version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "# Set Style\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = [12, 6]\n",
    "\n",
    "# Load Data (Prefer Enriched)\n",
    "ENRICHED_PATH = \"../data/processed/final_augmented_dataset_enriched.parquet\"\n",
    "STANDARD_PATH = \"../data/processed/final_augmented_dataset.parquet\"\n",
    "\n",
    "if os.path.exists(ENRICHED_PATH):\n",
    "    DATA_PATH = ENRICHED_PATH\n",
    "    print(f\"üîπ Loading Enriched Dataset: {ENRICHED_PATH}\")\n",
    "else:\n",
    "    DATA_PATH = STANDARD_PATH\n",
    "    print(f\"üî∏ Loading Standard Dataset: {STANDARD_PATH}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_parquet(DATA_PATH)\n",
    "    print(f\"‚úÖ Loaded {len(df):,} samples.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"‚ùå Dataset not found. Run pipeline or enrichment first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 1. Source Distribution\n",
    "Where is the data coming from? Visualizing the contribution of KoalaAI vs. others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_counts = df['source'].value_counts()\n",
    "print(source_counts)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.barplot(x=source_counts.index, y=source_counts.values, palette=\"viridis\")\n",
    "plt.title(\"Dataset Source Distribution\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.yscale('log')  # Log scale due to KoalaAI dominance\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 2. Category Balance (The 8 Taxonomy Classes)\n",
    "Are we balanced? (Spoiler: 'Safe' is usually dominant)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sentinel.utils.taxonomy import CATEGORY_NAMES\n",
    "\n",
    "# Flatten labels\n",
    "all_labels = [label for sublist in df['labels'] for label in sublist]\n",
    "label_counts = pd.Series(all_labels).map(CATEGORY_NAMES).value_counts()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(y=label_counts.index, x=label_counts.values, orient='h', palette=\"magma\")\n",
    "plt.title(\"Category Distribution (Log Scale)\")\n",
    "plt.xscale('log')\n",
    "plt.xlabel(\"Count (Log)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Exact Counts:\")\n",
    "print(label_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 3. Class Imbalance Ratio\n",
    "Checking which categories are under-represented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_class = label_counts.max()\n",
    "imbalance_ratios = majority_class / label_counts\n",
    "print(\"Imbalance Ratios (1 = Majority):\")\n",
    "print(imbalance_ratios.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 4. Text Length Analysis\n",
    "SLMs have limited context windows. How long are the inputs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate length, dropping NaNs/empty strings just in case\n",
    "df['char_length'] = df['text'].astype(str).str.len()\n",
    "valid_lengths = df['char_length'].dropna()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "# Use simple bins and log scale on Y axis manually for robustness\n",
    "sns.histplot(valid_lengths, bins=100, kde=False)\n",
    "plt.title(\"Text Length Distribution (Log Frequency)\")\n",
    "plt.xlabel(\"Characters\")\n",
    "plt.ylabel(\"Count (Log)\")\n",
    "plt.yscale('log') \n",
    "plt.xlim(0, 1000) # Zoom in on typical range\n",
    "plt.show()\n",
    "\n",
    "print(\"Length Stats:\")\n",
    "print(valid_lengths.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 5. Language Distribution\n",
    "Analyzing multilingual spread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'lang' in df.columns:\n",
    "    print(\"üîπ Using pre-calculated 'lang' column.\")\n",
    "    lang_counts = df['lang'].value_counts().head(20)\n",
    "else:\n",
    "    print(\"üî∏ 'lang' column not found. Estimating on sample (slow)...\")\n",
    "    try:\n",
    "        from langdetect import detect\n",
    "        def safe_detect(text):\n",
    "            try: return detect(text)\n",
    "            except: return \"unknown\"\n",
    "        sample_df = df.sample(n=5000, random_state=42)\n",
    "        lang_counts = sample_df['text'].apply(lambda x: safe_detect(str(x)[:500])).value_counts().head(20)\n",
    "    except ImportError:\n",
    "        print(\"langdetect not found. Run 'pip install langdetect'\")\n",
    "        lang_counts = pd.Series([])\n",
    "\n",
    "print(lang_counts)\n",
    "\n",
    "if not lang_counts.empty:\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    sns.barplot(x=lang_counts.index, y=lang_counts.values, palette=\"coolwarm\")\n",
    "    plt.title(\"Language Distribution (Top 20)\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
